{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df653a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataset import LinearDynamicalDataset, WHDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from model import GPTConfig, GPT\n",
    "import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a235fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall settings\n",
    "out_dir = \"out\"\n",
    "\n",
    "# System settings\n",
    "nu = 1\n",
    "ny = 1\n",
    "#seq_len = 600\n",
    "batch_size = 32 # 256\n",
    "fixed_system = True # Are we testing on a fixed system?\n",
    "model_seed = None\n",
    "\n",
    "# Compute settings\n",
    "cuda_device = \"cuda:2\"\n",
    "no_cuda = False\n",
    "threads = 32\n",
    "compile = True\n",
    "\n",
    "# Configure compute\n",
    "torch.set_num_threads(threads) \n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device_name  = cuda_device if use_cuda else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "device_type = 'cuda' if 'cuda' in device_name else 'cpu' # for later use in torch.autocast\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "#torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "#torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create out dir\n",
    "out_dir = Path(out_dir)\n",
    "#exp_data = torch.load(out_dir/\"ckpt_lin.pt\") # trained on linear models!\n",
    "#exp_data = torch.load(out_dir/\"ckpt_small_wh_last.pt\")\n",
    "#exp_data = torch.load(out_dir/\"ckpt_small_wh.pt\")\n",
    "#exp_data = torch.load(out_dir/\"ckpt_big.pt\", map_location=device)\n",
    "exp_data = torch.load(out_dir/\"ckpt_small_wh_adapt_last.pt\")\n",
    "cfg = exp_data[\"cfg\"]\n",
    "# For compatibility with initial experiment without seed\n",
    "try:\n",
    "    cfg.seed\n",
    "except AttributeError:\n",
    "    cfg.seed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c029f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = cfg.seq_len\n",
    "nx = cfg.nx\n",
    "model_seed = cfg.seed if model_seed is None else model_seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29395ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_smooth = pd.Series(exp_data[\"LOSS\"]).rolling(100).mean()\n",
    "#fig = go.Figure()\n",
    "#fig.add_trace(go.Scatter(y=exp_data[\"LOSS\"], name=\"TRAINING LOSS\", line_color=\"black\"))\n",
    "#fig.add_trace(go.Scatter(y=loss_smooth, name=\"TRAINING LOSS SMOOTH\", line_color=\"blue\"))\n",
    "#fig.add_trace(go.Scatter(x=np.arange(1, len(exp_data[\"LOSS_VAL\"])+1)*2000,\n",
    "#                         y=exp_data[\"LOSS_VAL\"], name=\"VAL LOSS\", line_color=\"red\")\n",
    "#             )\n",
    "#fig.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(exp_data[\"LOSS\"], label=\"TRAINING_LOSS\")\n",
    "plt.plot(loss_smooth, label=\"TRAINING_LOSS_SMOOTH\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34332c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = exp_data[\"model_args\"]\n",
    "gptconf = GPTConfig(**model_args)\n",
    "model = GPT(gptconf).to(device)\n",
    "\n",
    "\n",
    "state_dict = exp_data[\"model\"]\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "test_ds = WHDataset(nx=nx, nu=nu, ny=ny, seq_len=seq_len,\n",
    "                    model_seed=cfg.seed if fixed_system else None,\n",
    "                    data_seed=None, fixed_system=fixed_system)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, num_workers=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y, batch_u = next(iter(test_dl))\n",
    "batch_y = batch_y.to(device)\n",
    "batch_u = batch_u.to(device)\n",
    "with torch.no_grad():\n",
    "    batch_y_pred, loss = model(batch_u, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7478d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model in simulation from a certain time step!\n",
    "sim_start = 400 #seq_len//2#500\n",
    "batch_y_sim = torch.zeros_like(batch_y)\n",
    "batch_y_sim[:, :sim_start, :] = batch_y[:, :sim_start, :]\n",
    "with torch.no_grad():\n",
    "    for idx in range(sim_start, seq_len):\n",
    "        batch_y_t, _ = model(batch_u[:, :idx, :], batch_y_sim[:, :idx, :], compute_loss=False)\n",
    "        batch_y_sim[:, [idx], :] = batch_y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eef187",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_sim = batch_y_sim.to(\"cpu\").detach().numpy()\n",
    "batch_y_pred = batch_y_pred.to(\"cpu\").detach().numpy()\n",
    "batch_y = batch_y.to(\"cpu\").detach().numpy()\n",
    "batch_u = batch_u.to(\"cpu\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6dd590",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_target = batch_y[:, 1:, :] # target @ time k: y_{k+1}\n",
    "batch_y_pred = batch_y_pred[:, :-1, :] # prediction @ time k: y_{k+1|k}\n",
    "batch_y_sim = batch_y_sim[:, 1:, :] # simulation @ time k: y_{k+1|k}\n",
    "batch_y_pred_dummy = batch_y[:, :-1, :] # dummy estimator: y_{k+1} \\approx y_{k}\n",
    "batch_pred_err = batch_y_target - batch_y_pred\n",
    "batch_pred_err_dummy = batch_y_target - batch_y_pred_dummy\n",
    "batch_sim_err = batch_y_target - batch_y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"RMSE\")\n",
    "idx = 0\n",
    "plt.plot(batch_y_target[idx], 'k', label=\"True\")\n",
    "plt.plot(batch_y_pred[idx], 'b', label=\"Pred\")\n",
    "plt.plot(batch_y_sim[idx], 'g', label=\"Sim\")\n",
    "#plt.plot(batch_y_pred_dummy[idx], 'm', label=\"Pred dummy\")\n",
    "plt.plot(batch_pred_err[idx], 'r', label=\"Pred_Err\")\n",
    "plt.plot(batch_sim_err[idx], 'm', label=\"Sim_Err\")\n",
    "plt.axvline(x=sim_start, color=\"black\")\n",
    "#plt.plot(batch_y_target[idx] - batch_y_pred_dummy[idx], 'm', label=\"Err dummy\")\n",
    "plt.legend()\n",
    "#plt.xlim([0, 600]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aab2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(batch_pred_err_dummy.squeeze(-1).T, \"b\", alpha=0.4);\n",
    "plt.plot(batch_pred_err.squeeze(-1).T, \"r\", alpha=0.2);\n",
    "plt.plot(batch_sim_err.squeeze(-1).T, \"m\", alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34481aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchid import metrics\n",
    "skip = sim_start\n",
    "rmse_pred = metrics.rmse(batch_y_target[:, skip:, :], batch_y_pred[:, skip:, :], time_axis=1)\n",
    "rmse_sim = metrics.rmse(batch_y_target[:, skip:, :], batch_y_sim[:, skip:, :], time_axis=1)\n",
    "rmse_dummy = metrics.rmse(batch_y_target[:, skip:, :], batch_y_pred_dummy[:, skip:, :], time_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"RMSE\")\n",
    "plt.hist(rmse_dummy, color=\"blue\", label=\"dummy\");\n",
    "plt.hist(rmse_pred, color=\"red\", label=\"pred\");\n",
    "plt.hist(rmse_sim, color=\"magenta\", label=\"sim\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{rmse_pred.mean()=:.3f}, {rmse_sim.mean()=:.3f}, {rmse_dummy.mean()=:.3f}, {loss=:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e78c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
