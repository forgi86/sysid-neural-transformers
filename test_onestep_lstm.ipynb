{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fc536f",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from dataset import LinearDynamicalDataset, WHDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from lstm_onestep import LSTModel\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batch_u, batch_y, model, initial_sequence, one_step):\n",
    "    with torch.no_grad():\n",
    "        seq_length = batch_u.shape[1]\n",
    "        n_u = batch_u.shape[2]\n",
    "        n_y = batch_y.shape[2]\n",
    "        \n",
    "        input_seq = batch_u\n",
    "\n",
    "        start_zero = torch.zeros([1, 1, n_y])\n",
    "        input_y = batch_y[:, 0:init_sequence, :]\n",
    "        input_y = torch.cat((start_zero, input_y), dim=1)\n",
    "        zeros = torch.zeros([1,seq_length - init_sequence - 1, n_y])\n",
    "        input_y = torch.cat((input_y, zeros), dim=1)\n",
    "\n",
    "        input_seq = torch.cat((input_seq, input_y), dim=2)\n",
    "\n",
    "        total_loss = 0\n",
    "        for i in range(init_sequence, seq_length):\n",
    "            seq = input_seq[:, 0:i+1, :]\n",
    "            output, hidden = model(seq)\n",
    "            loss = criterion(output[0][-1][0], batch_y[0][i][0])\n",
    "            total_loss += loss\n",
    "            \n",
    "            if i+1 == seq_length:\n",
    "                break\n",
    "\n",
    "            if one_step:\n",
    "                input_seq[0][i+1][n_u] = batch_y[0][i][0]\n",
    "            else:\n",
    "                input_seq[0][i+1][n_u] = output[0][-1][0]\n",
    "\n",
    "        errors = (batch_y - output).detach().numpy()[0]\n",
    "        loss = criterion(output, batch_y)\n",
    "        predictions = output.detach().numpy()[0]\n",
    "\n",
    "        print(\"loss without initial sequence:\")\n",
    "        mean_loss = total_loss / (seq_length-init_sequence)\n",
    "        print(mean_loss.item())\n",
    "        \n",
    "        return predictions, errors\n",
    "    \n",
    "def plot_input_output(batch_u, batch_y, predictions, errors):\n",
    "    n_u = batch_u.shape[2]\n",
    "    fig, ax = plt.subplots(1, 1, sharex=True)\n",
    "\n",
    "    ax.set_title(\"Output\")\n",
    "    ax.plot(batch_y[0], c='black', label='y')\n",
    "    ax.plot(predictions, c='blue', label='天')\n",
    "    ax.plot(errors, c='red', label='y - 天')\n",
    "    ax.legend(prop={'size': 10})\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28584395",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 5\n",
    "nu = 1\n",
    "ny = 1\n",
    "\n",
    "exp_data = torch.load('out/ckpt_onestep_lin_lstm.pt', map_location=device)\n",
    "model_lstm = LSTModel(input_size=nu + ny, output_size=ny, hidden_dim=512, n_layers=4)\n",
    "model_lstm.load_state_dict(exp_data[\"model\"])\n",
    "model_lstm.eval()\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = LinearDynamicalDataset(nx=5, nu=1, ny=1, seq_len=100)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)\n",
    "init_sequence = 1\n",
    "one_step = True\n",
    "batch_y, batch_u = next(iter(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1faf3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lstm, errors_lstm = evaluate(batch_u, batch_y, model_lstm, init_sequence, one_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26339db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_input_output(batch_u, batch_y, predictions_lstm, errors_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd165c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Sequence\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.plot(errors_lstm.flatten(), label='LSTM', c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = LinearDynamicalDataset(nx=5, nu=1, ny=1, seq_len=400)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)\n",
    "\n",
    "actual_out = []\n",
    "errors = []\n",
    "for i in range(10):\n",
    "    batch_y, batch_u = next(iter(test_dl))\n",
    "    predictions_lstm, errors_lstm = evaluate(batch_u, batch_y, model_lstm, init_sequence, one_step)\n",
    "    actual_out.append(batch_u.flatten().tolist())\n",
    "    errors.append(errors_lstm.flatten().tolist())\n",
    "\n",
    "    \n",
    "custom_lines = [Line2D([0], [0], color='black'),\n",
    "                Line2D([0], [0], color='red')]\n",
    "plt.xlabel('time step (-)')\n",
    "for ao in actual_out:\n",
    "    plt.plot(ao, c='black')\n",
    "for err in errors:\n",
    "    plt.plot(err, c='red')\n",
    "plt.legend(custom_lines, ['y', 'y - 天'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wh = LSTModel(input_size=2, output_size=1, hidden_dim=512, n_layers=4)\n",
    "model_wh.load_state_dict(torch.load('trained_models/wh_lstm_model200000', map_location=device))\n",
    "\n",
    "test_ds = WHDataset(nx=5, nu=1, ny=1, seq_len=100)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)\n",
    "\n",
    "init_sequence = 1\n",
    "one_step = True\n",
    "batch_y, batch_u = next(iter(test_dl))\n",
    "\n",
    "predictions_wh, errors_wh = evaluate(batch_u, batch_y, model_wh, init_sequence, one_step)\n",
    "\n",
    "plot_input_output(batch_u, batch_y, predictions_wh, errors_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Sequence\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.plot(errors_wh.flatten(), c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa94fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wh = LSTModel(input_size=2, output_size=1, hidden_dim=512, n_layers=4)\n",
    "model_wh.load_state_dict(torch.load('trained_models/lstm_wh_model_1000000', map_location=device))\n",
    "\n",
    "test_ds = WHDataset(nx=5, nu=1, ny=1, seq_len=100)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)\n",
    "\n",
    "init_sequence = 1\n",
    "one_step = True\n",
    "batch_y, batch_u = next(iter(test_dl))\n",
    "\n",
    "predictions_wh, errors_wh = evaluate(batch_u, batch_y, model_wh, init_sequence, one_step)\n",
    "\n",
    "plot_input_output(batch_u, batch_y, predictions_wh, errors_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a421c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Sequence\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.plot(errors_wh.flatten(), c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = WHDataset(nx=5, nu=1, ny=1, seq_len=400)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)\n",
    "\n",
    "actual_out = []\n",
    "errors = []\n",
    "for i in range(10):\n",
    "    batch_y, batch_u = next(iter(test_dl))\n",
    "    predictions_wh, errors_wh = evaluate(batch_u, batch_y, model_wh, init_sequence, one_step)\n",
    "    actual_out.append(batch_u.flatten().tolist())\n",
    "    errors.append(errors_wh.flatten().tolist())\n",
    "\n",
    "    \n",
    "custom_lines = [Line2D([0], [0], color='black'),\n",
    "                Line2D([0], [0], color='red')]\n",
    "plt.xlabel('time step (-)')\n",
    "for ao in actual_out:\n",
    "    plt.plot(ao, c='black')\n",
    "for err in errors:\n",
    "    plt.plot(err, c='red')\n",
    "plt.legend(custom_lines, ['y', 'y - 天'])\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
