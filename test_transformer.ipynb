{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from dataset import LinearDynamicalDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from model_ts import GPTConfig, GPT\n",
    "import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c25428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall settings\n",
    "out_dir = \"out\"\n",
    "\n",
    "# System settings\n",
    "nx = 10\n",
    "nu = 1\n",
    "ny = 1\n",
    "seq_len = 400\n",
    "\n",
    "\n",
    "# Compute settings\n",
    "cuda_device = \"cuda:0\"\n",
    "no_cuda = True\n",
    "threads = 5\n",
    "compile = True\n",
    "\n",
    "# Create out dir\n",
    "out_dir = Path(out_dir)\n",
    "exp_data = torch.load(out_dir/\"ckpt.pt\")\n",
    "\n",
    "# Configure compute\n",
    "torch.set_num_threads(threads)\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device_name  = cuda_device if use_cuda else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "device_type = 'cuda' if 'cuda' in device_name else 'cpu' # for later use in torch.autocast\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "#torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "#torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "\n",
    "# Create data loader\n",
    "test_ds = LinearDynamicalDataset(nx=nx, nu=nu, ny=ny, seq_len=seq_len)\n",
    "test_dl = DataLoader(test_ds, batch_size=256, num_workers=threads)\n",
    "\n",
    "model_args = exp_data[\"model_args\"]\n",
    "gptconf = GPTConfig(**model_args)\n",
    "model = GPT(gptconf).to(device)\n",
    "\n",
    "\n",
    "state_dict = exp_data[\"model\"]\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cad475",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y, batch_u = next(iter(test_dl))\n",
    "with torch.no_grad():\n",
    "    batch_y_pred, loss = model(batch_u, batch_y)\n",
    "    batch_y_pred = batch_y_pred.detach().numpy()\n",
    "    batch_y = batch_y.detach().numpy()\n",
    "    batch_u = batch_u.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e17c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_target = batch_y[:, 1:, :] # target @ time k: y_{k+1}\n",
    "batch_y_pred = batch_y_pred[:, :-1, :] # prediction @ time k: y_{k+1|k}\n",
    "batch_y_pred_dummy = batch_y[:, :-1, :] # dummy estimator: y_{k+1} \\approx y_{k}\n",
    "batch_pred_err = batch_y_target - batch_y_pred\n",
    "batch_pred_err_dummy = batch_y_target - batch_y_pred_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=exp_data[\"LOSS\"], name=\"TRAINING LOSS\", line_color=\"black\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c418c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"RMSE\")\n",
    "idx = 4\n",
    "plt.plot(batch_y_target[idx], 'k', label=\"True\")\n",
    "plt.plot(batch_y_pred[idx], 'b', label=\"Pred\")\n",
    "#plt.plot(batch_y_pred_dummy[idx], 'm', label=\"Pred dummy\")\n",
    "plt.plot(batch_y_target[idx] - batch_y_pred[idx], 'r', label=\"Err\")\n",
    "#plt.plot(batch_y_target[idx] - batch_y_pred_dummy[idx], 'm', label=\"Err dummy\")\n",
    "plt.legend()\n",
    "plt.xlim([0, 100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(batch_pred_err_dummy.squeeze(-1).T, \"r\");\n",
    "plt.plot(batch_pred_err.squeeze(-1).T, \"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchid import metrics\n",
    "skip = 50\n",
    "rmse_transformer = metrics.rmse(batch_y_target[:, skip:, :], batch_y_pred[:, skip:, :], time_axis=1)\n",
    "rmse_dummy = metrics.rmse(batch_y_target[:, skip:, :], batch_y_pred_dummy[:, skip:, :], time_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"RMSE\")\n",
    "plt.hist(rmse_dummy, color=\"red\", label=\"dummy\");\n",
    "plt.hist(rmse_transformer, color=\"black\", label=\"transformer\");\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
